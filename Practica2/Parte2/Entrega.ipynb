{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "70b05e29",
   "metadata": {},
   "source": [
    "# 3.1 De batch a streaming\n",
    "\n",
    "En esta sección comparamos dos enfoques sobre el conjunto de datos **Electricity (Elec2)**:\n",
    "\n",
    "1. **Enfoque batch (Scikit-learn)**  \n",
    "   - Convertimos el flujo de datos en un `DataFrame` de pandas.  \n",
    "   - Entrenamos un `GaussianNB` de Scikit-learn sobre un subconjunto de entrenamiento.  \n",
    "   - Evaluamos sobre un subconjunto de test, respetando el orden temporal (sin barajar).\n",
    "\n",
    "2. **Enfoque streaming (River)**  \n",
    "   - Entrenamos un `GaussianNB` de River de forma incremental.  \n",
    "   - Evaluamos con *evaluación progresiva*: en cada instante predecimos primero y después actualizamos el modelo.\n",
    "\n",
    "Finalmente comparamos las precisiones obtenidas.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f61036ab",
   "metadata": {},
   "source": [
    "## GaussianNB batch (Scikit-learn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b7d45b3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://maxhalford.github.io/files/datasets/electricity.zip (697.72 KiB)\n",
      "Uncompressing into C:\\Users\\jorge\\river_data\\Elec2\n",
      "Shape del DataFrame: (45312, 9)\n",
      "   date  day    period  nswprice  nswdemand  vicprice  vicdemand  transfer  \\\n",
      "0   0.0    2  0.000000  0.056443   0.439155  0.003467   0.422915  0.414912   \n",
      "1   0.0    2  0.021277  0.051699   0.415055  0.003467   0.422915  0.414912   \n",
      "2   0.0    2  0.042553  0.051489   0.385004  0.003467   0.422915  0.414912   \n",
      "3   0.0    2  0.063830  0.045485   0.314639  0.003467   0.422915  0.414912   \n",
      "4   0.0    2  0.085106  0.042482   0.251116  0.003467   0.422915  0.414912   \n",
      "\n",
      "   target  \n",
      "0    True  \n",
      "1    True  \n",
      "2    True  \n",
      "3    True  \n",
      "4   False  \n",
      "Precisión GaussianNB (Scikit-learn, batch): 0.7539\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from river import datasets\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# 1) Convertir el flujo Elec2 a DataFrame de pandas\n",
    "elec_stream = datasets.Elec2()\n",
    "\n",
    "rows = []\n",
    "for x, y in elec_stream:\n",
    "    row = dict(x)\n",
    "    row['target'] = y\n",
    "    rows.append(row)\n",
    "\n",
    "df_elec = pd.DataFrame(rows)\n",
    "print(\"Shape del DataFrame:\", df_elec.shape)\n",
    "print(df_elec.head())\n",
    "\n",
    "# 2) Separar X, y\n",
    "X = df_elec.drop(columns=['target'])\n",
    "y = df_elec['target']\n",
    "\n",
    "# 3) Codificar variables categóricas (por ejemplo 'day')\n",
    "X_encoded = pd.get_dummies(X)\n",
    "\n",
    "# 4) Partición train/test respetando el orden (shuffle=False)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_encoded, y, test_size=0.3, shuffle=False\n",
    ")\n",
    "\n",
    "# 5) Entrenar GaussianNB batch de Scikit-learn\n",
    "gnb_batch = GaussianNB()\n",
    "gnb_batch.fit(X_train, y_train)\n",
    "\n",
    "# 6) Evaluar\n",
    "y_pred_test = gnb_batch.predict(X_test)\n",
    "acc_batch = accuracy_score(y_test, y_pred_test)\n",
    "\n",
    "print(f\"Precisión GaussianNB (Scikit-learn, batch): {acc_batch:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffe3a295",
   "metadata": {},
   "source": [
    "## GaussianNB streaming (River, evaluación progresiva)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c97b787",
   "metadata": {},
   "outputs": [],
   "source": [
    "from river import naive_bayes, metrics, preprocessing, compose, datasets\n",
    "\n",
    "# 1) Definir modelo GaussianNB de River con preprocesado:\n",
    "#    - OneHotEncoder para categóricas\n",
    "model_gnb_stream = compose.Pipeline(\n",
    "    preprocessing.OneHotEncoder(),\n",
    "    naive_bayes.GaussianNB()\n",
    ")\n",
    "\n",
    "# 2) Métrica de evaluación progresiva\n",
    "metric_stream = metrics.Accuracy()\n",
    "\n",
    "progressive_acc_gnb = []\n",
    "\n",
    "# 3) Recorrer el flujo en orden\n",
    "dataset_stream = datasets.Elec2()\n",
    "\n",
    "for i, (x, y) in enumerate(dataset_stream):\n",
    "    # Predicción antes de aprender\n",
    "    y_pred = model_gnb_stream.predict_one(x)\n",
    "    \n",
    "    # Actualizar métrica\n",
    "    metric_stream.update(y, y_pred)\n",
    "    progressive_acc_gnb.append(metric_stream.get())\n",
    "    \n",
    "    # Aprender con el ejemplo actual\n",
    "    model_gnb_stream.learn_one(x, y)\n",
    "\n",
    "print(f\"Precisión final GaussianNB (River, progresiva): {metric_stream.get():.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a08b044",
   "metadata": {},
   "source": [
    "## Comparación rápida batch vs streaming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da86aaf8",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'AAGE2 (Python 3.11.0)' requires the ipykernel package.\n",
      "\u001b[1;31m<a href='command:jupyter.createPythonEnvAndSelectController'>Create a Python Environment</a> with the required packages.\n",
      "\u001b[1;31mOr install 'ipykernel' using the command: 'conda install -n AAGE2 ipykernel --update-deps --force-reinstall'"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Curva de precisión progresiva del modelo streaming\n",
    "plt.figure(figsize=(8,4))\n",
    "plt.plot(progressive_acc_gnb)\n",
    "plt.xlabel(\"Instante (nº de ejemplo en el flujo)\")\n",
    "plt.ylabel(\"Precisión acumulada\")\n",
    "plt.title(\"GaussianNB (River) - Evaluación progresiva\")\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "print(f\"Precisión GaussianNB batch (Scikit-learn): {acc_batch:.4f}\")\n",
    "print(f\"Precisión final GaussianNB streaming (River): {metric_stream.get():.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5add4733",
   "metadata": {},
   "source": [
    "# 3.2 Manejo de *concept drift* con ADWIN\n",
    "\n",
    "En esta parte integramos el detector de cambios **ADWIN** en el flujo de datos:\n",
    "\n",
    "- Usamos un `GaussianNB` de River como clasificador base.\n",
    "- Alimentamos a ADWIN con el error (0 si acierta, 1 si falla).\n",
    "- Cuando ADWIN detecta un cambio relevante:\n",
    "  - **Estrategia**: reiniciamos el modelo (lo re-inicializamos desde cero).\n",
    "  - Guardamos el instante en el que se ha producido el *drift* para visualizarlo.\n",
    "\n",
    "Así obtenemos una versión de GaussianNB que se “resetea” cuando cambia el concepto.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd4e6ab1",
   "metadata": {},
   "source": [
    "## GaussianNB + ADWIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "792fbffc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from river import drift\n",
    "\n",
    "# Modelo base: GaussianNB con OneHotEncoder\n",
    "def make_gnb_model():\n",
    "    return compose.Pipeline(\n",
    "        preprocessing.OneHotEncoder(),\n",
    "        naive_bayes.GaussianNB()\n",
    "    )\n",
    "\n",
    "model_gnb_drift = make_gnb_model()\n",
    "metric_gnb_drift = metrics.Accuracy()\n",
    "adwin = drift.ADWIN()\n",
    "\n",
    "progressive_acc_gnb_drift = []\n",
    "drift_points = []\n",
    "\n",
    "dataset_stream = datasets.Elec2()\n",
    "\n",
    "for i, (x, y) in enumerate(dataset_stream):\n",
    "    # Predicción antes de aprender\n",
    "    y_pred = model_gnb_drift.predict_one(x)\n",
    "    \n",
    "    # Actualizar métrica\n",
    "    metric_gnb_drift.update(y, y_pred)\n",
    "    progressive_acc_gnb_drift.append(metric_gnb_drift.get())\n",
    "    \n",
    "    # Actualizar ADWIN con el error (1 si fallo, 0 si acierto)\n",
    "    error = int(y_pred != y)\n",
    "    adwin.update(error)\n",
    "    \n",
    "    # Si ADWIN detecta *drift*, reiniciamos el modelo\n",
    "    if adwin.drift_detected:\n",
    "        print(f\"Drift detectado en t = {i}. Reiniciando modelo.\")\n",
    "        drift_points.append(i)\n",
    "        model_gnb_drift = make_gnb_model()\n",
    "        adwin = drift.ADWIN()\n",
    "    \n",
    "    # Aprendizaje\n",
    "    model_gnb_drift.learn_one(x, y)\n",
    "\n",
    "print(f\"Precisión final GaussianNB + ADWIN: {metric_gnb_drift.get():.4f}\")\n",
    "print(f\"Nº de drifts detectados: {len(drift_points)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec4ee555",
   "metadata": {},
   "source": [
    "## Comparar GNB “normal” vs GNB + ADWIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4d37053",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,4))\n",
    "plt.plot(progressive_acc_gnb, label=\"GNB streaming (sin ADWIN)\")\n",
    "plt.plot(progressive_acc_gnb_drift, label=\"GNB + ADWIN\")\n",
    "for t in drift_points:\n",
    "    plt.axvline(t, linestyle=\"--\", alpha=0.3)  # línea vertical en cada drift\n",
    "\n",
    "plt.xlabel(\"Instante (nº de ejemplo en el flujo)\")\n",
    "plt.ylabel(\"Precisión acumulada\")\n",
    "plt.title(\"Comparación GaussianNB: sin/ con ADWIN\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42b4b9e2",
   "metadata": {},
   "source": [
    "# 3.3 Modelos adaptativos: HAT y Adaptive Random Forest\n",
    "\n",
    "A continuación construimos modelos adaptativos en River:\n",
    "\n",
    "- Un *pipeline* que combina:\n",
    "  - `OneHotEncoder` (para manejar atributos categóricos).\n",
    "  - `StandardScaler` (para normalizar atributos numéricos).\n",
    "  - Un **Hoeffding Adaptive Tree (HAT)**.\n",
    "\n",
    "- Un **Adaptive Random Forest (ARF)** que utiliza como árboles base modelos adaptativos.\n",
    "\n",
    "Para ambos modelos generamos curvas de evaluación progresiva sobre el flujo `Elec2` y las comparamos.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a6e339b",
   "metadata": {},
   "source": [
    "## Función de evaluación progresiva"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9633ae14",
   "metadata": {},
   "outputs": [],
   "source": [
    "from river import tree, ensemble\n",
    "\n",
    "def progressive_evaluation(model, dataset):\n",
    "    \"\"\"Evalúa un modelo River de forma progresiva sobre un dataset en flujo.\n",
    "    \n",
    "    Devuelve:\n",
    "      - lista con la precisión acumulada en cada instante\n",
    "      - métrica final (Accuracy)\n",
    "    \"\"\"\n",
    "    metric = metrics.Accuracy()\n",
    "    history = []\n",
    "    \n",
    "    for i, (x, y) in enumerate(dataset):\n",
    "        y_pred = model.predict_one(x)\n",
    "        metric.update(y, y_pred)\n",
    "        history.append(metric.get())\n",
    "        model.learn_one(x, y)\n",
    "    \n",
    "    return history, metric\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad59b885",
   "metadata": {},
   "source": [
    "## HAT (Hoeffding Adaptive Tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84a17638",
   "metadata": {},
   "outputs": [],
   "source": [
    "from river import preprocessing, compose\n",
    "\n",
    "# Pipeline HAT: OneHotEncoder + StandardScaler + HAT\n",
    "hat_model = compose.Pipeline(\n",
    "    preprocessing.OneHotEncoder(),\n",
    "    preprocessing.StandardScaler(),\n",
    "    tree.HoeffdingAdaptiveTreeClassifier()\n",
    ")\n",
    "\n",
    "dataset_hat = datasets.Elec2()\n",
    "acc_hat_history, acc_hat_metric = progressive_evaluation(hat_model, dataset_hat)\n",
    "\n",
    "print(f\"Precisión final HAT: {acc_hat_metric.get():.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce8ed3da",
   "metadata": {},
   "source": [
    "## Adaptive Random Forest (ARF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e804b36d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pipeline ARF: OneHotEncoder + StandardScaler + AdaptiveRandomForest\n",
    "arf_model = compose.Pipeline(\n",
    "    preprocessing.OneHotEncoder(),\n",
    "    preprocessing.StandardScaler(),\n",
    "    ensemble.AdaptiveRandomForestClassifier(\n",
    "        n_models=10,      # nº de árboles en el bosque\n",
    "        seed=42\n",
    "    )\n",
    ")\n",
    "\n",
    "dataset_arf = datasets.Elec2()\n",
    "acc_arf_history, acc_arf_metric = progressive_evaluation(arf_model, dataset_arf)\n",
    "\n",
    "print(f\"Precisión final ARF: {acc_arf_metric.get():.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47a37490",
   "metadata": {},
   "source": [
    "## Comparar curvas HAT vs ARF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d6bc3e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,4))\n",
    "plt.plot(acc_hat_history, label=\"HAT\")\n",
    "plt.plot(acc_arf_history, label=\"Adaptive Random Forest\")\n",
    "plt.xlabel(\"Instante (nº de ejemplo en el flujo)\")\n",
    "plt.ylabel(\"Precisión acumulada\")\n",
    "plt.title(\"Evaluación progresiva: HAT vs Adaptive Random Forest\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59371b84",
   "metadata": {},
   "source": [
    "# 3.4 Preguntas de análisis\n",
    "\n",
    "### 3.4.1 ¿Por qué HAT o ARF tienden a superar a GNB con *concept drift*?\n",
    "\n",
    "El modelo **Gaussian Naive Bayes (GNB)** asume que:\n",
    "- Las características son condicionalmente independientes dadas la clase.\n",
    "- La distribución de cada atributo para cada clase es (normalmente) gaussiana y **estacionaria**.\n",
    "\n",
    "En un escenario con *concept drift*:\n",
    "\n",
    "- Las distribuciones de los atributos y/o la relación entre atributos y clase **cambian con el tiempo**.\n",
    "- GNB mantiene un único conjunto de parámetros globales que se va actualizando con todos los datos vistos.  \n",
    "  Si el concepto cambia de forma relevante, el modelo arrastra “memoria” del pasado que ya no es representativa.\n",
    "- Además, la suposición de independencia condicional limita la capacidad para capturar interacciones complejas entre variables.\n",
    "\n",
    "En cambio, modelos **adaptativos** como **HAT** o **ARF**:\n",
    "\n",
    "- Se basan en árboles de decisión incrementales que dividen el espacio en regiones, aprendiendo reglas locales.\n",
    "- Incorporan mecanismos explícitos de detección y adaptación al *drift* (por ejemplo, uso de detectores tipo ADWIN en nodos).\n",
    "- Pueden reemplazar ramas o subárboles cuando dejan de ser útiles, ajustándose mejor a los nuevos patrones.\n",
    "- Capturan interacciones no lineales y dependencias entre características sin asumir independencia.\n",
    "\n",
    "Por todo ello, en presencia de cambios conceptuales, HAT y ARF suelen mantener una precisión más alta y estable a lo largo del tiempo que un GNB simple.\n",
    "\n",
    "---\n",
    "\n",
    "### 3.4.2 ¿Por qué ARF suele ser más robusto que HAT?\n",
    "\n",
    "**Adaptive Random Forest (ARF)** es un **ensamblado** de múltiples árboles adaptativos (por ejemplo, HATs), entrenados con:\n",
    "\n",
    "- **Bagging online** (poniendo pesos aleatorios a cada ejemplo para cada árbol).\n",
    "- **Selección aleatoria de subconjuntos de atributos** en cada división (como en Random Forest clásico).\n",
    "\n",
    "Esto aporta varias ventajas:\n",
    "\n",
    "1. **Reducción de la varianza**  \n",
    "   - Un único HAT puede ser muy sensible a cambios en una parte concreta del flujo de datos.  \n",
    "   - ARF combina muchos árboles y promedia sus predicciones, suavizando el efecto de ruido y drifts locales.\n",
    "\n",
    "2. **Diversidad de modelos**  \n",
    "   - Cada árbol ve una versión ligeramente distinta del flujo (por el muestreo tipo bagging) y de las características.  \n",
    "   - Si el concepto cambia, es probable que algunos árboles se adapten más rápido que otros, manteniendo buen rendimiento global.\n",
    "\n",
    "3. **Sustitución dinámica de árboles**  \n",
    "   - ARF suele incorporar detectores de *drift* por árbol.  \n",
    "   - Cuando un árbol empieza a funcionar mal o se detecta *drift*, puede ser reemplazado por uno nuevo entrenado con los datos recientes.  \n",
    "   - Este mecanismo de “renovación” hace que el bosque se mantenga actualizado y robusto frente a cambios prolongados.\n",
    "\n",
    "4. **Mayor estabilidad en presencia de ruido**  \n",
    "   - El voto mayoritario del conjunto reduce el impacto de ejemplos ruidosos que podrían desestabilizar un único HAT.\n",
    "\n",
    "Como consecuencia, **ARF suele ser más robusto** que un árbol adaptativo individual (HAT) en escenarios de datos en flujo con *concept drift* y ruido, alcanzando precisiones más altas y con menor variabilidad.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AAGE2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
